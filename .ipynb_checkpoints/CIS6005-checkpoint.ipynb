{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cfd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "garm_data = pd.read_csv('garments_worker_productivity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "garm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15661579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns with null values or non contributing values\n",
    "garm_data_input = garm_data.drop('wip', axis = 1)\n",
    "garm_data_input = garm_data_input.drop('date', axis = 1)\n",
    "garm_data_input = garm_data_input.drop('actual_productivity', axis = 1)\n",
    "garm_data_output = garm_data[['actual_productivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding columns \n",
    "columnsToEncode = ['quarter', 'department', 'day']\n",
    "\n",
    "for col in columnsToEncode:\n",
    "    distinct_values = garm_data_input[col].unique()\n",
    "    mapping_dict = dict(zip(distinct_values, range(1, len(distinct_values) + 1)))\n",
    "    garm_data_input[col] = garm_data_input[col].replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4195144",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "garm_data_inputs = scaler.fit_transform(garm_data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe59557",
   "metadata": {},
   "source": [
    "# Initial test to change values in single column\n",
    "\n",
    "distinctVal = garm_data['quarter'].unique()\n",
    "map_distinctVal = dict(zip(distinctVal, range(1, len(distinctVal)+1)))\n",
    "garm_data['quarter'] = garm_data['quarter'].replace(map_distinctVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "garm_data_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3717d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "garm_data_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6e8c0",
   "metadata": {},
   "source": [
    "# Creating the sigmoid activation function and sigmoid derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the sigmoid Function\n",
    "def sigmoid(sum):\n",
    "  return 1 / (1 + np.exp(-sum))\n",
    "\n",
    "#This is the sigmoid derivative as used before\n",
    "def sigmoid_derivative(sigmoid):\n",
    "  return sigmoid * (1 - sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20225da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = garm_data_input.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9aa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = garm_data_output.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e31b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating random wieghts for all features\n",
    "weights_hidden = np.random.rand(inputs.shape[1], hidden_neurons)*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e67fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_output = np.random.rand(hidden_neurons, 1) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7755c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08894a29",
   "metadata": {},
   "source": [
    "#Defining model\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "error = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  input_layer = inputs\n",
    "  sum_synapse0 = np.dot(input_layer, weights_hidden)\n",
    "  hidden_layer = sigmoid(sum_synapse0)\n",
    "\n",
    "  sum_synapse1 = np.dot(hidden_layer, weights_output)\n",
    "  output_layer = sigmoid(sum_synapse1)\n",
    "\n",
    "  error_output_layer = output - output_layer\n",
    "  average = np.mean(abs(error_output_layer))\n",
    "    #print after every specified range of the value\n",
    "  if epoch % 25 == 0:\n",
    "    print('Epoch: ' + str(epoch + 1) + ' Error: ' + str(average))\n",
    "    error.append(average)\n",
    "  \n",
    "  derivative_output = sigmoid_derivative(output_layer)\n",
    "  delta_output = error_output_layer * derivative_output\n",
    "  \n",
    "  weights1T = weights_output.T\n",
    "  delta_output_weight = delta_output.dot(weights1T)\n",
    "  delta_hidden_layer = delta_output_weight * sigmoid_derivative(hidden_layer)\n",
    "  \n",
    "  hidden_layerT = hidden_layer.T\n",
    "  input_x_delta1 = hidden_layerT.dot(delta_output)\n",
    "  weights_1 = weights_output + (input_x_delta1 * learning_rate)\n",
    "  \n",
    "  input_layerT = input_layer.T\n",
    "  input_x_delta0 = input_layerT.dot(delta_hidden_layer)\n",
    "  weights_0 = weights_hidden + (input_x_delta0 * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fa7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "learning_rate = 0.1\n",
    "error = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    input_layer = inputs\n",
    "    sum_synapse0 = np.dot(input_layer, weights_hidden)\n",
    "    hidden_layer = sigmoid(sum_synapse0)\n",
    "\n",
    "    sum_synapse1 = np.dot(hidden_layer, weights_output)\n",
    "    output_layer = sigmoid(sum_synapse1)\n",
    "\n",
    "    error_output_layer = output - output_layer\n",
    "    average = np.mean(abs(error_output_layer))\n",
    "\n",
    "    # Print error and append to list after each epoch\n",
    "    print('Epoch:', epoch + 1, 'Error:', average)\n",
    "    error.append(average)\n",
    "\n",
    "    # Backpropagation and weight updates\n",
    "    derivative_output = sigmoid_derivative(output_layer)\n",
    "    delta_output = error_output_layer * derivative_output\n",
    "\n",
    "    weights1T = weights_output.T\n",
    "    delta_output_weight = delta_output.dot(weights1T)\n",
    "    delta_hidden_layer = delta_output_weight * sigmoid_derivative(hidden_layer)\n",
    "\n",
    "    hidden_layerT = hidden_layer.T\n",
    "    input_x_delta1 = hidden_layerT.dot(delta_output)\n",
    "    weights_output += (input_x_delta1 * learning_rate)  # Update weights_output directly\n",
    "\n",
    "    input_layerT = input_layer.T\n",
    "    input_x_delta0 = input_layerT.dot(delta_hidden_layer)\n",
    "    weights_hidden += (input_x_delta0 * learning_rate)  # Update weights_hidden directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ab297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
